
from legged_gym.envs.base.legged_robot import LeggedRobot

from isaacgym.torch_utils import *
from isaacgym import gymtorch, gymapi, gymutil
from legged_gym.utils.isaacgym_utils import get_euler_xyz as get_euler_xyz_in_tensor
from legged_gym.datasets.motion_loader_g1 import G1_AMPLoader
import torch
import cv2
import torch.nn.functional as F
import numpy as np

class ym1_16Dof_Loco_Robot(LeggedRobot):
    def __init__(self, cfg, sim_params, physics_engine, sim_device, headless):
        super().__init__(cfg, sim_params, physics_engine, sim_device, headless)
        self.amp_motion_files = self.cfg.env.amp_motion_files
        self.num_amp_obs = self.cfg.env.num_amp_obs
        if self.cfg.env.reference_state_initialization: # NOTE only for visualize reference motion
            self.amp_loader = G1_AMPLoader(motion_dir=self.amp_motion_files, device=self.device, time_between_frames=self.dt)
            self.motion_reference = self.amp_loader.get_joint_pose_batch_16dof(torch.cat(self.amp_loader.trajectories_full, dim=0))
        
        # Body mask æ”¯æŒ - é¢„åŠ è½½æ•°æ®ï¼Œä½†æ ¹æ® iteration åŠ¨æ€å¯ç”¨
        self.body_mask_enabled = False  # åˆå§‹ç¦ç”¨
        if hasattr(self.cfg.depth, 'body_mask_path'):
            try:
                body_mask_data = np.load(self.cfg.depth.body_mask_path, allow_pickle=True)
                self.body_masks = body_mask_data['body_masks']
                print(f"âœ… Body mask æ•°æ®å·²åŠ è½½: {self.body_masks.shape[0]} ä¸ª masks")
                print(f"   å°†åœ¨ {self.cfg.depth.body_mask_start_iter} iterations åå¯ç”¨")
            except Exception as e:
                print(f"âš ï¸  Body mask åŠ è½½å¤±è´¥: {e}")
                self.body_masks = None
        else:
            self.body_masks = None
        
    def get_amp_observations(self):
        return self.dof_pos
    
    def check_and_enable_body_mask(self, current_iter):
        """
        æ£€æŸ¥å½“å‰ iteration å¹¶åŠ¨æ€å¯ç”¨ body mask
        
        Args:
            current_iter: å½“å‰è®­ç»ƒ iteration
        """
        if self.body_masks is not None and not self.body_mask_enabled:
            if current_iter >= self.cfg.depth.body_mask_start_iter:
                self.body_mask_enabled = True
                self.cfg.depth.add_body_mask = True  # åŒæ—¶å¯ç”¨é…ç½®æ ‡å¿—
                print(f"\n{'='*60}")
                print(f"ğŸ­ Body Mask å·²å¯ç”¨ (iteration {current_iter})")
                print(f"   è·¯å¾„: {self.cfg.depth.body_mask_path}")
                print(f"{'='*60}\n")

    def _get_noise_scale_vec(self, cfg):
        """ Sets a vector used to scale the noise added to the observations.
            [NOTE]: Must be adapted when changing the observations structure

        Args:
            cfg (Dict): Environment config file

        Returns:
            [torch.Tensor]: Vector of scales used to multiply a uniform distribution in [-1, 1]
        """
        noise_vec = torch.zeros_like(self.obs_buf[0])
        self.add_noise = self.cfg.noise.add_noise
        noise_scales = self.cfg.noise.noise_scales
        noise_level = self.cfg.noise.noise_level
        noise_vec[:3] = 0. # commands
        noise_vec[3:6] = noise_scales.ang_vel * noise_level * self.obs_scales.ang_vel
        noise_vec[6:9] = noise_scales.gravity * noise_level
        noise_vec[9:9+self.num_actions] = noise_scales.dof_pos * noise_level * self.obs_scales.dof_pos
        noise_vec[9+self.num_actions:9+2*self.num_actions] = noise_scales.dof_vel * noise_level * self.obs_scales.dof_vel
        noise_vec[9+2*self.num_actions:9+3*self.num_actions] = 0. # previous actions
        
        return noise_vec

    def _init_buffers(self):
        super()._init_buffers()
        self.last_last_actions = torch.zeros(self.num_envs, self.num_actions, dtype=torch.float, device=self.device, requires_grad=False)
        self.last_feet_contact_force = torch.zeros(self.num_envs, 2, 3, dtype=torch.float, device=self.device, requires_grad=False)
        self.last_last_feet_contact_force = torch.zeros(self.num_envs, 2, 3, dtype=torch.float, device=self.device, requires_grad=False)
        self.feet_indicator_offset = torch.tensor(self.cfg.asset.feet_indicator_offset, dtype=torch.float, device=self.device, requires_grad=False)
        self.feet_indicator_pos = torch.zeros(self.num_envs, len(self.feet_indices), *self.feet_indicator_offset.shape,dtype=torch.float, device=self.device, requires_grad=False)
        
        self.feet_collision_indicator_offset = torch.tensor(self.cfg.asset.feet_collision_indicator_offset, dtype=torch.float, device=self.device, requires_grad=False)
        self.feet_collision_indicator_pos = torch.zeros(self.num_envs, len(self.feet_indices), *self.feet_collision_indicator_offset.shape,dtype=torch.float, device=self.device, requires_grad=False)


        # æ­¥æ€ç›¸ä½å˜é‡ - ç”¨äºå¼ºåˆ¶äº¤æ›¿æ­¥æ€
        self.gait_phase = torch.zeros(self.num_envs, dtype=torch.float, device=self.device, requires_grad=False)
        self.gait_frequency = 1.5  # æ­¥æ€é¢‘ç‡ Hzï¼Œçº¦0.67ç§’ä¸€ä¸ªå®Œæ•´å‘¨æœŸ
        self.last_swing_foot = torch.zeros(self.num_envs, dtype=torch.long, device=self.device)  # 0=å·¦è„š, 1=å³è„š
        
        # è¿½è¸ªæ¯åªè„šçš„æœ€è¿œå‰è¿›ä½ç½®ï¼ˆç”¨äºé˜²æ­¢å¹¶æ­¥ï¼‰
        self.feet_max_forward_pos = torch.zeros(self.num_envs, 2, dtype=torch.float, device=self.device, requires_grad=False)  # [å·¦è„š, å³è„š]

    def reset_idx(self, env_ids):
        super().reset_idx(env_ids)
        self.last_actions[env_ids] = 0.
        self.last_last_actions[env_ids] = 0.
        self.last_feet_contact_force[env_ids] = 0.
        self.last_last_feet_contact_force[env_ids] = 0.
        # é‡ç½®åŒè„šç€åœ°è®¡æ—¶å™¨
        if hasattr(self, 'both_feet_contact_time'):
            self.both_feet_contact_time[env_ids] = 0.
        # é‡ç½®æ­¥æ€ç›¸ä½
        if hasattr(self, 'gait_phase'):
            self.gait_phase[env_ids] = 0.
            self.last_swing_foot[env_ids] = 0
        # é‡ç½®è„šçš„æœ€è¿œå‰è¿›ä½ç½®
        if hasattr(self, 'feet_max_forward_pos'):
            self.feet_max_forward_pos[env_ids] = 0.
        
        # === æ–°å¢ [2026-01-23]: é‡ç½®åœ°å½¢è®°å¿†å˜é‡ ===
        # ä¿®æ”¹åŠ¨æœº: è§£å†³æ¥¼é¡¶ç›²åŒºé—®é¢˜å¼•å…¥äº†è®°å¿†æœºåˆ¶ï¼Œæœºå™¨äººçœ‹åˆ°æ¥¼æ¢¯åä¼šä¿æŒé«˜æŠ¬è…¿ä¸€æ®µæ—¶é—´
        # ä½†é‡ç½®æ—¶å¿…é¡»æ¸…ç©ºè®°å¿†ï¼Œå¦åˆ™æœºå™¨äººé‡ç”Ÿåˆ°å¹³åœ°æ—¶ä¼šç»§ç»­é«˜æŠ¬è…¿
        # if hasattr(self, 'avg_obstacle_height'):
        #     self.avg_obstacle_height[env_ids] = 0.

    def _draw_foot_indicator(self):
        self.gym.clear_lines(self.viewer)
        sphere_geom = gymutil.WireframeSphereGeometry(0.01, 10, 10, None, color=(1, 0, 0))
        indicator_pos = self.feet_indicator_pos.reshape(-1, 3)
        for i, point in enumerate(indicator_pos):
            pose = gymapi.Transform(gymapi.Vec3(point[0], point[1], point[2]), r=None)
            gymutil.draw_lines(
                sphere_geom, self.gym, self.viewer, self.envs[self.lookat_id], pose
            )

    def _reset_dofs(self, env_ids):
        if self.cfg.init_state.random_default_pos:
            rand_default_pos = self.motion_reference[np.random.randint(0, self.motion_reference.shape[0], size=(env_ids.shape[0], )), :]
            self.dof_pos[env_ids] = rand_default_pos * torch_rand_float(0.5, 1.5, (len(env_ids), self.num_dof), device=self.device)
        else:
            # å‡å°åˆå§‹éšæœºèŒƒå›´ï¼Œä» 0.5~1.5 æ”¹ä¸º 0.95~1.05ï¼Œè®©æœºå™¨äººæ›´ç¨³å®šåœ°å¼€å§‹
            self.dof_pos[env_ids] = self.default_dof_pos * torch_rand_float(0.95, 1.05, (len(env_ids), self.num_dof), device=self.device)
        self.dof_vel[env_ids] = 0.

        env_ids_int32 = env_ids.to(dtype=torch.int32)
        self.gym.set_dof_state_tensor_indexed(self.sim,
                                              gymtorch.unwrap_tensor(self.dof_state),
                                              gymtorch.unwrap_tensor(env_ids_int32), len(env_ids_int32))

    def post_physics_step(self):
        """ check terminations, compute observations and rewards
            calls self._post_physics_step_callback() for common computations 
            calls self._draw_debug_vis() if needed
        """
        self.gym.refresh_actor_root_state_tensor(self.sim)
        self.gym.refresh_net_contact_force_tensor(self.sim)
        self.gym.refresh_force_sensor_tensor(self.sim)
        self.gym.refresh_rigid_body_state_tensor(self.sim)

        self.episode_length_buf += 1
        self.common_step_counter += 1

        # prepare quantities
        self.base_pos[:] = self.root_states[:, 0:3]
        self.base_quat[:] = self.root_states[:, 3:7]
        self.rpy[:] = get_euler_xyz_in_tensor(self.base_quat[:])
        self.base_lin_vel[:] = quat_rotate_inverse(self.base_quat, self.root_states[:, 7:10])
        self.base_ang_vel[:] = quat_rotate_inverse(self.base_quat, self.root_states[:, 10:13])
        self.projected_gravity[:] = quat_rotate_inverse(self.base_quat, self.gravity_vec)

        self.feet_pos = self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.feet_indices, 0:3]
        self.feet_vel = self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.feet_indices, 7:10]

        contact = self.contact_forces[:, self.feet_indices, 2] > 1.
        self.contact_filt = torch.logical_or(contact, self.last_contacts)
        self.contact_over = torch.logical_and(~contact, self.last_contacts)
        self.last_contacts = contact

        # [Modified] Move callback up to ensure measured_heights is updated before reward computation
        self._post_physics_step_callback()

        # compute observations, rewards, resets, ...
        self.check_termination()
        self.compute_reward()
        env_ids = self.reset_buf.nonzero(as_tuple=False).flatten()
        terminal_amp_states = self.get_amp_observations()[env_ids]
        terminal_obs, terminal_critic_obs = self.compute_observations()
        self.reset_idx(env_ids)

        self.update_depth_buffer()
        self.warp_update_depth_buffer()
        
        if self.cfg.domain_rand.push_robots:
            self._push_robots()

        self.compute_observations() # in some cases a simulation step might be required to refresh some obs (for example body positions)
        
        self.last_last_actions[:] = torch.clone(self.last_actions[:])
        self.last_actions[:] = self.actions[:]
        self.last_last_feet_contact_force[:] = torch.clone(self.last_feet_contact_force[:])
        self.last_feet_contact_force[:] = self.contact_forces[:, self.feet_indices]

        self.last_dof_vel[:] = self.dof_vel[:]
        self.last_root_vel[:] = self.root_states[:, 7:13]

        if self.viewer and self.enable_viewer_sync and self.debug_viz:
            if self.cfg.depth.use_camera and self.cfg.depth.warp_camera:
                window_name = "Depth Image"
                cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
                cv2.imshow("Depth Image", self.depth_buffer[self.lookat_id, -1].cpu().numpy() + 0.5)
                cv2.waitKey(1)
                window_name = "Warp Depth Image"
                cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
                cv2.imshow("Warp Depth Image", self.warp_depth_buffer[self.lookat_id, -1].cpu().numpy() + 0.5)
                cv2.waitKey(1)
            elif self.cfg.depth.warp_camera:
                window_name = "Warp Depth Image"
                cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
                cv2.imshow("Warp Depth Image", self.warp_depth_buffer[self.lookat_id, -1].cpu().numpy() + 0.5)
                cv2.waitKey(1)
            elif self.cfg.depth.use_camera:
                window_name = "Depth Image"
                cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
                cv2.imshow("Depth Image", self.depth_buffer[self.lookat_id, -1].cpu().numpy() + 0.5)
                cv2.waitKey(1)

            # self._draw_foot_indicator()
    
        return env_ids, terminal_amp_states, terminal_obs[env_ids], terminal_critic_obs[env_ids]

    def _post_physics_step_callback(self):
        self.compute_both_feet_info()
        self.compute_feet_indicator_pos()
        self.compute_feet_collision_indicator_pos()
        
        return super()._post_physics_step_callback()
    
    def compute_both_feet_info(self):
        # compute both feet swing length
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        cur_footvel_translated = self.feet_vel - self.root_states[:, 7:10].unsqueeze(1)
        for i in range(len(self.feet_indices)):
            self.footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
            self.footvel_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footvel_translated[:, i, :])
    
    def compute_feet_indicator_pos(self):
        num_dot = self.feet_indicator_offset.shape[0]
        ankle_quat = self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.feet_indices, 3:7]
        feet_offset = self.feet_indicator_offset.view(1, 1, num_dot, 3).expand(self.num_envs, 2, num_dot, 3)
        quat_expanded = ankle_quat.unsqueeze(2).expand(-1, -1, num_dot, -1)  # (num_envs, 2, num_dot, 4)
        rotated_points = quat_apply(quat_expanded.reshape(-1, 4), feet_offset.reshape(-1, 3))
        rotated_points = rotated_points.view(self.num_envs, 2, num_dot, 3)
        self.feet_indicator_pos = rotated_points + self.feet_pos.unsqueeze(2)  # (num_envs, 2, num_dot, 3)


    def compute_feet_collision_indicator_pos(self):
        # collision indicator
        num_dot = self.feet_collision_indicator_offset.shape[0]
        ankle_quat = self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.feet_indices, 3:7]
        feet_offset = self.feet_collision_indicator_offset.view(1, 1, num_dot, 3).expand(self.num_envs, 2, num_dot, 3)
        quat_expanded = ankle_quat.unsqueeze(2).expand(-1, -1, num_dot, -1)  # (num_envs, 2, num_dot, 4)
        rotated_points = quat_apply(quat_expanded.reshape(-1, 4), feet_offset.reshape(-1, 3))
        rotated_points = rotated_points.view(self.num_envs, 2, num_dot, 3)
        self.feet_collision_indicator_pos = rotated_points + self.feet_pos.unsqueeze(2)  # (num_envs, 2, num_dot, 3)

    
    def check_termination(self):
        """ Check if environments need to be reset
        """
        self.reset_buf = torch.any(torch.norm(self.contact_forces[:, self.termination_contact_indices, :], dim=-1) > 1000., dim=1)
        # self.reset_buf |= torch.logical_or(torch.abs(self.rpy[:,1])>1.0, torch.abs(self.rpy[:,0])>0.8)  # å·²ç¦ç”¨: ä¸å†å› roll/pitchè§’åº¦è¿‡å¤§è€Œé‡ç½®
        self.reset_buf |= (self._get_base_heights() < 0.4)

        if self.cfg.terrain.mesh_type == "trimesh":
            offset_y = torch.abs(self.root_states[:, 1] - self.origin_y)
            only_forward_env = torch.logical_and(self.env_class != 0, self.env_class != 1)
            self.reset_buf |= torch.logical_and(only_forward_env, offset_y>1.0)
        
        self.time_out_buf = self.episode_length_buf > self.max_episode_length # no terminal reward for time-outs
        self.reset_buf |= self.time_out_buf

    
    def compute_observations(self):
        """ Computes observations
        """
        self.obs_buf = torch.cat((  self.commands[:, :3] * self.commands_scale,
                                    self.base_ang_vel * self.obs_scales.ang_vel,
                                    self.projected_gravity,
                                    (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos,
                                    self.dof_vel * self.obs_scales.dof_vel,
                                    self.actions,
                                    ),dim=-1)
        
        self.privileged_obs_buf = torch.cat((  self.base_lin_vel * self.obs_scales.lin_vel,
                                    self.base_ang_vel  * self.obs_scales.ang_vel,
                                    self.projected_gravity,
                                    self.commands[:, :3] * self.commands_scale,
                                    (self.dof_pos - self.default_dof_pos) * self.obs_scales.dof_pos,
                                    self.dof_vel * self.obs_scales.dof_vel,
                                    self.actions,
                                    ),dim=-1)

        if self.cfg.env.feet_info:  # 6 * 2 = 12
            self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, self.footpos_in_body_frame.reshape(self.num_envs, -1), 
                                                 self.footvel_in_body_frame.reshape(self.num_envs, -1)), dim=-1)
        
        if self.cfg.env.foot_force_info:  # 6
            contact_force = self.sensor_forces.flatten(1) * self.obs_scales.contact_force
            self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, contact_force), dim=-1)
        
        if self.cfg.env.priv_info:  # 32 + 1 + 1 + 1 + 3 = 38
            self.privileged_obs_buf= torch.cat((self.privileged_obs_buf, self.root_states[:, 2].unsqueeze(-1)), dim=-1)

            if self.cfg.domain_rand.randomize_friction:  # 1
                self.privileged_obs_buf= torch.cat((self.privileged_obs_buf, self.randomized_frictions), dim=-1)

            if (self.cfg.domain_rand.randomize_base_mass):  # 1
                self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, self.randomized_added_masses), dim=-1)

            if (self.cfg.domain_rand.randomize_com_pos):  # 3
                self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, self.randomized_com_pos * self.obs_scales.com_pos), dim=-1)

            if (self.cfg.domain_rand.randomize_gains):  # 16 * 2
                self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, (self.randomized_p_gains / self.p_gains - 1) * self.obs_scales.pd_gains), dim=-1)
                self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, (self.randomized_d_gains / self.d_gains - 1) * self.obs_scales.pd_gains), dim=-1)
        
        if self.cfg.terrain.measure_heights:  # 187
            heights = torch.clip(self.root_states[:, 2].unsqueeze(1) - self.cfg.normalization.base_height - self.measured_heights, -1, 1.) * self.obs_scales.height_measurements
            self.privileged_obs_buf = torch.cat((self.privileged_obs_buf, heights), dim=-1)
            
        # add perceptive inputs if not blind
        # add noise if needed
        if self.add_noise:
            self.obs_buf += (2 * torch.rand_like(self.obs_buf) - 1) * self.noise_scale_vec

        return self.obs_buf, self.privileged_obs_buf

    def compute_reward(self):
        """ Compute rewards
            Calls each reward function which had a non-zero scale (processed in self._prepare_reward_function())
            adds each terms to the episode sums and to the total reward
        """
        self.rew_buf[:] = 0.
        for i in range(len(self.reward_functions)):
            name = self.reward_names[i]
            rew = self.reward_functions[i]() * self.reward_scales[name]
            self.rew_buf += rew
            self.episode_sums[name] += rew
        if self.cfg.rewards.only_positive_rewards:
            self.rew_buf[:] = torch.clip(self.rew_buf[:], min=0.)
        # add termination reward after clipping
        if "termination" in self.reward_scales:
            rew = self._reward_termination() * self.reward_scales["termination"]
            self.rew_buf += rew
            self.episode_sums["termination"] += rew

    def _resample_commands(self, env_ids):
        """ Randommly select commands of some environments

        Args:
            env_ids (List[int]): Environments ids for which new commands are needed
        """
        super()._resample_commands(env_ids)

        only_forward_env = torch.logical_and(self.env_class != 0, self.env_class != 1)
        self.commands[only_forward_env, 3] = 0
        self.commands[only_forward_env, 2] = 0
        self.commands[only_forward_env, 1] = 0
        self.commands[only_forward_env, 0] = torch.abs(self.commands[only_forward_env, 0])
    
    #------------ reward functions----------------
    def _reward_tracking_lin_vel(self):
        # Tracking of linear velocity commands (xy axes)
        lin_vel_error = torch.sum(torch.square(self.commands[:, :2] - self.base_lin_vel[:, :2]), dim=1)
        return torch.exp(-lin_vel_error/self.cfg.rewards.tracking_sigma)
    
    def _reward_tracking_ang_vel(self):
        # Tracking of angular velocity commands (yaw) 
        ang_vel_error = torch.square(self.commands[:, 2] - self.base_ang_vel[:, 2])
        return torch.exp(-ang_vel_error/self.cfg.rewards.tracking_sigma)
    
    def _reward_dof_acc(self):
        # Penalize dof accelerations
        return torch.sum(torch.square((self.last_dof_vel - self.dof_vel) / self.dt), dim=1)
    
    def _reward_dof_vel(self):
        # Penalize dof velocities
        return torch.sum(torch.square(self.dof_vel), dim=1)
    
    def _reward_action_rate(self):
        # Penalize changes in actions
        return torch.sum(torch.square(self.last_actions - self.actions), dim=1)
    
    def _reward_action_smoothness(self):
        """
        Encourages smoothness in the robot's actions by penalizing large differences between consecutive actions.
        This is important for achieving fluid motion and reducing mechanical stress.
        """
        # æ¯ä¸ªå…³èŠ‚çš„ä¸€é˜¶å·®åˆ†ï¼ˆåŠ¨ä½œå˜åŒ–ï¼‰
        term_1_per_joint = torch.square(self.last_actions - self.actions)
        # æ¯ä¸ªå…³èŠ‚çš„äºŒé˜¶å·®åˆ†ï¼ˆåŠ é€Ÿåº¦å˜åŒ–ï¼‰
        term_2_per_joint = torch.square(self.actions + self.last_last_actions - 2 * self.last_actions)
        # æ¯ä¸ªå…³èŠ‚çš„åŠ¨ä½œå¹…åº¦
        term_3_per_joint = 0.05 * torch.abs(self.actions)
        
        # æ¯ä¸ªå…³èŠ‚çš„æ€»æƒ©ç½š
        per_joint_penalty = term_1_per_joint + term_2_per_joint + term_3_per_joint
        
        # åˆå§‹åŒ–å…³èŠ‚åç§°
        if not hasattr(self, '_smoothness_joint_names'):
            self._smoothness_joint_names = self.dof_names
            self._smoothness_step_counter = 0
            print(f"\nç›‘æ§åŠ¨ä½œå¹³æ»‘åº¦å…³èŠ‚: {self._smoothness_joint_names}")
        
        self._smoothness_step_counter += 1
        
        # æ¯ 24 æ­¥æ‰“å°ä¸€æ¬¡
        if self._smoothness_step_counter % 24 == 0:
            # è®¡ç®—æ¯ä¸ªå…³èŠ‚çš„å¹³å‡æƒ©ç½š
            joint_penalties = per_joint_penalty.mean(dim=0).cpu().numpy()
            total_penalty = per_joint_penalty.sum(dim=1).mean().item()
            
            # æ‰¾å‡ºæƒ©ç½šæœ€å¤§çš„å‰5ä¸ªå…³èŠ‚
            sorted_indices = joint_penalties.argsort()[::-1][:5]
            
            penalty_info = []
            for idx in sorted_indices:
                name = self._smoothness_joint_names[idx]
                penalty = joint_penalties[idx]
                # ç®€åŒ–å…³èŠ‚åç§°
                short_name = name.replace('_joint', '').replace('left_', 'L_').replace('right_', 'R_')
                penalty_info.append(f"{short_name}:{penalty:.2f}")
            
            print(f"[å¹³æ»‘åº¦] æ€»:{total_penalty:.1f} | Top5: {' | '.join(penalty_info)}")
        
        return per_joint_penalty.sum(dim=1)

    def _reward_ang_vel_xy(self):
        # Penalize xy axes base angular velocity
        return torch.sum(torch.square(self.base_ang_vel[:, :2]), dim=1)
    
    def _reward_orientation(self):
        # Penalize non flat base orientation
        return torch.sum(torch.square(self.projected_gravity[:, :2]), dim=1)
    
    def _reward_base_height(self):
        # Penalize base height deviating from target (relative to feet, not world frame)
        # è®¡ç®— base åˆ°è„šåº•çš„ç›¸å¯¹é«˜åº¦ï¼Œè€Œä¸æ˜¯ä¸–ç•Œåæ ‡ç³»çš„ç»å¯¹é«˜åº¦
        base_height = self.root_states[:, 2]  # base çš„ Z åæ ‡
        
        # è·å–ä¸¤åªè„šçš„å¹³å‡é«˜åº¦ä½œä¸ºåœ°é¢å‚è€ƒ
        feet_height = self.feet_pos[:, :, 2].mean(dim=1)  # ä¸¤åªè„šçš„å¹³å‡ Z åæ ‡
        
        # è®¡ç®— base ç›¸å¯¹äºè„šåº•çš„é«˜åº¦
        relative_height = base_height - feet_height
        
        target_height = self.cfg.rewards.base_height_target
        
        # åˆå§‹åŒ–è®¡æ•°å™¨
        if not hasattr(self, '_base_height_step_counter'):
            self._base_height_step_counter = 0
        
        self._base_height_step_counter += 1
        
        # æ¯ 24 æ­¥æ‰“å°ä¸€æ¬¡
        if self._base_height_step_counter % 24 == 0:
            mean_rel_height = relative_height.mean().item()
            min_rel_height = relative_height.min().item()
            max_rel_height = relative_height.max().item()
            mean_abs_height = base_height.mean().item()
            print(f"[Baseé«˜åº¦] ç›®æ ‡:{target_height:.3f}m | ç›¸å¯¹é«˜åº¦:{mean_rel_height:.3f}m | ç»å¯¹é«˜åº¦:{mean_abs_height:.3f}m")
        
        # æƒ©ç½šç›¸å¯¹é«˜åº¦åç¦»ç›®æ ‡
        rew = torch.square(relative_height - target_height)
        return rew
    
    def _reward_joint_power(self):
        # Penalize high power
        return torch.sum(torch.abs(self.dof_vel) * torch.abs(self.torques), dim=1)

    def _reward_feet_clearance(self):
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        cur_footvel_translated = self.feet_vel - self.root_states[:, 7:10].unsqueeze(1)
        footvel_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
            footvel_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footvel_translated[:, i, :])
        height_error = torch.square(footpos_in_body_frame[:, :, 2] - self.cfg.rewards.clearance_height_target).view(self.num_envs, -1)
        foot_leteral_vel = torch.sqrt(torch.sum(torch.square(footvel_in_body_frame[:, :, :2]), dim=2)).view(self.num_envs, -1)
        return torch.sum(height_error * foot_leteral_vel, dim=1)
    
    def _reward_feet_stumble(self):
        # Penalize feet hitting vertical surfaces
        rew = torch.any(torch.norm(self.contact_forces[:, self.feet_indices, :2], dim=2) >\
             3 *torch.abs(self.contact_forces[:, self.feet_indices, 2]), dim=1)
        return rew.float()
    
    def _reward_torques(self):
        # Penalize torques
        return torch.sum(torch.square(self.torques), dim=1)

    def _reward_arm_joint_deviation(self):
        return torch.square(torch.norm(torch.abs(self.dof_pos[:, 12:] - self.default_dof_pos[:, 12:]), dim=1))

    def _reward_hip_joint_deviation(self):
        return torch.square(torch.norm(torch.abs(self.dof_pos[:, [1, 2, 7, 8]]), dim=1))
    
    def _reward_leg_joint_deviation(self):
        """
        æƒ©ç½šè…¿éƒ¨å…³èŠ‚ï¼ˆhip_pitch, kneeï¼‰åç¦»é»˜è®¤ä½ç½®å¤ªå¤šï¼Œä¿æŒè‡ªç„¶ç«™å§¿
        å…³èŠ‚ç´¢å¼•: 0=left_leg_pitch, 3=left_knee, 6=right_leg_pitch, 9=right_knee
        """
        leg_indices = [0, 3, 6, 9]  # leg_pitch å’Œ knee å…³èŠ‚
        deviation = self.dof_pos[:, leg_indices] - self.default_dof_pos[:, leg_indices]
        return torch.sum(torch.square(deviation), dim=1)
    
    def _reward_knee_hyperextension(self):
        """
        ä¸¥å‰æƒ©ç½šè†å…³èŠ‚åå±ˆï¼ˆè´Ÿè§’åº¦ï¼‰ï¼Œé˜²æ­¢è†ç›–å‘åå¼¯
        å…³èŠ‚ç´¢å¼•: 3=left_knee, 9=right_knee
        """
        knee_indices = [3, 9]
        knee_pos = self.dof_pos[:, knee_indices]
        # è†å…³èŠ‚è§’åº¦å°äº0.05å¼§åº¦æ—¶æƒ©ç½š
        hyperextension = torch.clamp(0.05 - knee_pos, min=0)
        return torch.sum(torch.square(hyperextension) * 100, dim=1)
    
    def _reward_ankle_deviation(self):
        """
        æƒ©ç½šè„šè¸å…³èŠ‚åç¦»é»˜è®¤ä½ç½®å¤ªå¤šï¼Œé˜²æ­¢è¿‡åº¦èƒŒå±ˆ/è·–å±ˆ
        å…³èŠ‚ç´¢å¼•: 4=left_ankle_pitch, 10=right_ankle_pitch
        """
        ankle_pitch_indices = [4, 10]
        ankle_pos = self.dof_pos[:, ankle_pitch_indices]
        default_ankle = self.default_dof_pos[:, ankle_pitch_indices]
        
        # å…è®¸ä¸€å®šèŒƒå›´çš„åç¦»ï¼ˆÂ±0.5 rad â‰ˆ Â±30Â°ï¼‰ï¼Œè¶…å‡ºåˆ™æƒ©ç½š
        deviation = torch.abs(ankle_pos - default_ankle)
        excess = torch.clamp(deviation - 0.5, min=0)
        return torch.sum(torch.square(excess), dim=1)

    def _reward_dof_pos_limits(self):
        # Penalize dof positions too close to the limit
        out_of_limits = -(self.dof_pos - self.dof_pos_limits[:, 0]).clip(max=0.) # lower limit
        out_of_limits += (self.dof_pos - self.dof_pos_limits[:, 1]).clip(min=0.)
        return torch.sum(out_of_limits, dim=1)
    
    def _reward_dof_vel_limits(self):
        # Penalize dof velocities too close to the limit
        # clip to max error = 1 rad/s per joint to avoid huge penalties
        return torch.sum((torch.abs(self.dof_vel) - self.dof_vel_limits*self.cfg.rewards.soft_dof_vel_limit).clip(min=0., max=1.), dim=1)
    
    def _reward_torque_limits(self):
        # penalize torques too close to the limit
        return torch.sum((torch.abs(self.torques) - self.torque_limits*self.cfg.rewards.soft_torque_limit).clip(min=0.), dim=1)

    def _reward_no_fly(self):
        is_jump =  torch.all(self.contact_forces[:, self.feet_indices, 2] < 1, dim=1)
        return is_jump.float()
    
    def _reward_feet_lateral_distance(self):
        # Penalize feet lateral distance deviating from target
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
        
        # è®¡ç®—å®é™…æ¨ªå‘è·ç¦»ï¼ˆå–ç»å¯¹å€¼ï¼‰
        actual_lateral_distance = torch.abs(footpos_in_body_frame[:, 0, 1] - footpos_in_body_frame[:, 1, 1])
        
        # è®¡ç®—å‰åé—´è·ï¼ˆXæ–¹å‘ï¼‰
        actual_longitudinal_distance = torch.abs(footpos_in_body_frame[:, 0, 0] - footpos_in_body_frame[:, 1, 0])
        
        # åˆå§‹åŒ–è®¡æ•°å™¨
        if not hasattr(self, '_lateral_dist_step_counter'):
            self._lateral_dist_step_counter = 0
        
        self._lateral_dist_step_counter += 1
        
        # æ¯ 24 æ­¥æ‰“å°ä¸€æ¬¡
        if self._lateral_dist_step_counter % 24 == 0:
            mean_dist = actual_lateral_distance.mean().item()
            min_dist = actual_lateral_distance.min().item()
            max_dist = actual_lateral_distance.max().item()
            target = self.cfg.rewards.feet_min_lateral_distance_target
            mean_long = actual_longitudinal_distance.mean().item()
            print(f"[è„šé—´è·] æ¨ªå‘ç›®æ ‡:{target:.3f}m | æ¨ªå‘:{mean_dist:.3f}m | å‰å:{mean_long:.3f}m")
        
        # æƒ©ç½šåç¦»ç›®æ ‡çš„è·ç¦»ï¼ˆå¹³æ–¹æƒ©ç½šï¼‰
        rew = torch.square(actual_lateral_distance - self.cfg.rewards.feet_min_lateral_distance_target)
        return rew
    
    def _reward_feet_longitudinal_distance(self):
        """
        æƒ©ç½šå‰åè„šï¼ˆä¸¤è„šåœ¨Xæ–¹å‘çš„é—´è·è¿‡å¤§ï¼‰ï¼Œé¼“åŠ±åŒè„šä¿æŒå¹³è¡Œ
        åªåœ¨é›¶é€Ÿåº¦å‘½ä»¤æ—¶ç”Ÿæ•ˆ
        """
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
        
        # è®¡ç®—å‰åé—´è·ï¼ˆXæ–¹å‘ï¼‰ï¼Œç›®æ ‡æ˜¯å°½é‡å°
        actual_longitudinal_distance = torch.abs(footpos_in_body_frame[:, 0, 0] - footpos_in_body_frame[:, 1, 0])
        
        # åªåœ¨åŒè„šéƒ½ç€åœ°æ—¶æƒ©ç½šå‰åè„šï¼ˆæ‘†åŠ¨æ—¶å…è®¸å‰åå·®å¼‚ï¼‰
        both_contact = torch.all(self.contact_filt, dim=1)
        
        # åªåœ¨é›¶é€Ÿåº¦å‘½ä»¤æ—¶ç”Ÿæ•ˆ
        cmd_norm = torch.norm(self.commands[:, :2], dim=1)
        no_cmd = cmd_norm < 0.1
        
        # å¹³æ–¹æƒ©ç½šï¼Œç›®æ ‡æ˜¯0ï¼ˆåŒè„šå¹³è¡Œï¼‰
        target = getattr(self.cfg.rewards, 'feet_longitudinal_distance_target', 0.05)
        rew = torch.square(actual_longitudinal_distance - target) * both_contact.float() * no_cmd.float()
        return rew
    
    def _reward_feet_slippage(self):
        return torch.sum(torch.norm(self.feet_vel, dim=-1) * (torch.norm(self.contact_forces[:, self.feet_indices, :], dim=-1) > 1.), dim=1)
    
    def _reward_feet_contact_force(self):
        # penalize high contact forces
        return torch.sum(F.relu(self.contact_forces[:, self.feet_indices, 2] - self.cfg.rewards.feet_contact_force_range[0]), dim=-1)
    
    def _reward_feet_force_rate(self):
        return torch.sum(F.relu(self.contact_forces[:, self.feet_indices, 2] - self.last_feet_contact_force[..., 2]), dim=-1)
    
    def _reward_feet_contact_momentum(self):
        """
        Penalizes the momentum of the feet contact forces, encouraging a more stable and controlled motion.
        foot vel * contact force
        """
        feet_contact_force = self.contact_forces[:, self.feet_indices, 2]
        feet_vertical_vel = self.feet_vel[:, :, 2]
        rew = torch.sum(torch.abs(feet_contact_force * feet_vertical_vel), dim=-1)
        return rew
    
    def _reward_collision(self):
        # Penalize collisions on selected bodies
        contact_forces_norm = torch.norm(self.contact_forces[:, self.penalised_contact_indices, :], dim=-1)
        has_collision = (contact_forces_norm > 0.1)
        
        # åˆå§‹åŒ–
        if not hasattr(self, '_collision_body_names'):
            self._collision_body_names = []
            body_names = self.gym.get_actor_rigid_body_names(self.envs[0], self.actor_handles[0])
            for idx in self.penalised_contact_indices:
                self._collision_body_names.append(body_names[idx])
            print(f"\nç›‘æ§ç¢°æ’éƒ¨ä½: {self._collision_body_names}")
            self._step_counter = 0
        
        self._step_counter += 1
        
        # æ¯ 24 æ­¥ï¼ˆä¸€ä¸ª iterationï¼‰æ‰“å°ä¸€æ¬¡
        if self._step_counter % 24 == 0:
            collision_counts = has_collision.sum(dim=0).cpu().numpy()
            total_collisions = has_collision.sum().item()
            
            if total_collisions > 0:
                collision_info = []
                for i, (name, count) in enumerate(zip(self._collision_body_names, collision_counts)):
                    if count > 0:
                        percentage = count / self.num_envs * 100
                        collision_info.append(f"{name}:{count}({percentage:.0f}%)")
                print(f"[ç¢°æ’] æ€»:{total_collisions:.0f} | {' | '.join(collision_info)}")
        
        return torch.sum(1. * has_collision, dim=1)
        
        # return torch.sum(1. * has_collision, dim=1)

    def _reward_feet_air_time(self):
        # Reward long steps
        # Need to filter the contacts because the contact reporting of PhysX is unreliable on meshes
        first_contact = (self.feet_air_time > 0.) * self.contact_filt
        self.feet_air_time += self.dt
        rew_airTime = torch.sum((self.feet_air_time - 0.5) * first_contact, dim=1) # reward only on first contact with the ground
        rew_airTime *= torch.norm(self.commands[:, :2], dim=1) > 0.1 #no reward for zero command
        self.feet_air_time *= ~self.contact_filt
        return rew_airTime
    
    # def _reward_single_foot_contact(self):
    #     """
    #     å¥–åŠ±å•è„šç€åœ°ï¼ˆäº¤æ›¿æ­¥æ€ï¼‰ï¼Œæƒ©ç½šåŒè„šåŒæ—¶ç€åœ°æˆ–åŒæ—¶ç¦»åœ°
    #     """
    #     # æ£€æµ‹æ¯åªè„šæ˜¯å¦ç€åœ°
    #     contact = self.contact_filt  # shape: (num_envs, 2) å·¦è„šå’Œå³è„š
        
    #     # åªæœ‰ä¸€åªè„šç€åœ°æ—¶å¥–åŠ±ï¼ˆå¼‚æˆ–æ“ä½œï¼‰
    #     single_contact = contact[:, 0] ^ contact[:, 1]  # å·¦è„š XOR å³è„š
        
    #     # åªåœ¨æœ‰é€Ÿåº¦å‘½ä»¤æ—¶æ‰å¥–åŠ±
    #     has_command = torch.norm(self.commands[:, :2], dim=1) > 0.1
        
    #     return single_contact.float() * has_command.float()
    
    def _reward_single_foot_contact(self):
        """
        é€Ÿåº¦è‡ªé€‚åº”çš„æ­¥æ€å¥–åŠ±ï¼š
        - ç«™ç«‹ (<0.15 m/s)ï¼šå¥–åŠ±åŒè„šç€åœ°ï¼Œä¿æŒç¨³å®š
        - æ…¢èµ° (0.15~0.4 m/s)ï¼šå…è®¸åŒæ”¯æ’‘æœŸï¼Œè½»å¾®å¥–åŠ±å•è„š
        - å¿«èµ° (>0.4 m/s)ï¼šå¼ºåˆ¶å•è„šæ”¯æ’‘ï¼Œäº¤æ›¿æ­¥æ€
        """
        contact = self.contact_filt  # shape: (num_envs, 2) å·¦è„šå’Œå³è„š
        single_contact = contact[:, 0] ^ contact[:, 1]  # åªæœ‰ä¸€åªè„šç€åœ°
        both_contact = torch.all(contact, dim=1)  # åŒè„šéƒ½ç€åœ°
        
        cmd_vel = torch.norm(self.commands[:, :2], dim=1)
        
        # ä¸‰ä¸ªé€Ÿåº¦åŒºé—´
        is_standing = cmd_vel < 0.15       # ç«™ç«‹
        is_slow_walk = (cmd_vel >= 0.15) & (cmd_vel < 0.4)  # æ…¢èµ°
        is_fast_walk = cmd_vel >= 0.4      # å¿«èµ°
        
        # ç«™ç«‹ï¼šå¥–åŠ±åŒè„šç€åœ°ï¼Œä¿æŒç¨³å®š
        stand_reward = both_contact.float() * is_standing.float()
        
        # æ…¢èµ°ï¼šè½»å¾®å¥–åŠ±å•è„šï¼Œä½†ä¹Ÿæ¥å—åŒè„šï¼ˆå…è®¸æ›´é•¿åŒæ”¯æ’‘æœŸï¼‰
        slow_walk_reward = (single_contact.float() * 0.5 + both_contact.float() * 0.3) * is_slow_walk.float()
        
        # å¿«èµ°ï¼šå¼ºçƒˆå¥–åŠ±å•è„šï¼Œé¼“åŠ±äº¤æ›¿æ­¥æ€
        fast_walk_reward = single_contact.float() * is_fast_walk.float()
        
        return stand_reward + slow_walk_reward + fast_walk_reward

    def _reward_alternating_gait(self):
        """
        å¼ºåˆ¶äº¤æ›¿æ­¥æ€ï¼šæƒ©ç½šåŒè„šåŒæ—¶ç€åœ°æ—¶é—´è¿‡é•¿
        é¼“åŠ±æœºå™¨äººå¿«é€Ÿåˆ‡æ¢æ”¯æ’‘è„šï¼Œè€Œä¸æ˜¯åŒè„šåŒæ—¶ç«™åœ¨åŒä¸€å°é˜¶
        """
        # åŒè„šéƒ½ç€åœ°
        both_contact = torch.all(self.contact_filt, dim=1)
        
        # åˆå§‹åŒ–åŒè„šç€åœ°è®¡æ—¶å™¨
        if not hasattr(self, 'both_feet_contact_time'):
            self.both_feet_contact_time = torch.zeros(self.num_envs, device=self.device)
        
        # æ›´æ–°è®¡æ—¶å™¨
        self.both_feet_contact_time = torch.where(
            both_contact,
            self.both_feet_contact_time + self.dt,
            torch.zeros_like(self.both_feet_contact_time)
        )
        
        # åªåœ¨æœ‰é€Ÿåº¦å‘½ä»¤æ—¶æƒ©ç½š
        has_command = torch.norm(self.commands[:, :2], dim=1) > 0.1
        
        # åŒè„šç€åœ°è¶…è¿‡0.15ç§’å¼€å§‹æƒ©ç½šï¼ˆå…è®¸çŸ­æš‚çš„åŒæ”¯æ’‘ç›¸ï¼‰
        penalty = F.relu(self.both_feet_contact_time - 0.15) * has_command.float()
        
        return penalty
    
    def _reward_step_length(self):
        """
        å¥–åŠ±è¾ƒå¤§çš„æ­¥é•¿ï¼Œé¼“åŠ±æœºå™¨äººè¿ˆå¤§æ­¥è€Œä¸æ˜¯å°ç¢æ­¥
        """
        # è®¡ç®—ä¸¤è„šåœ¨å‰è¿›æ–¹å‘çš„è·ç¦»å·®
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
        
        # å‰åè„šè·ç¦»ï¼ˆXæ–¹å‘ï¼‰
        step_length = torch.abs(footpos_in_body_frame[:, 0, 0] - footpos_in_body_frame[:, 1, 0])
        
        # åªåœ¨å•è„šç€åœ°æ—¶å¥–åŠ±æ­¥é•¿ï¼ˆæ‘†åŠ¨ç›¸ï¼‰
        single_contact = self.contact_filt[:, 0] ^ self.contact_filt[:, 1]
        
        # åªåœ¨æœ‰é€Ÿåº¦å‘½ä»¤æ—¶å¥–åŠ±
        has_command = torch.norm(self.commands[:, :2], dim=1) > 0.1
        
        # å¥–åŠ±æ­¥é•¿ï¼Œç›®æ ‡çº¦0.3m
        rew = torch.clamp(step_length, 0, 0.4) * single_contact.float() * has_command.float()
        
        return rew
    
    def _reward_gait_phase(self):
        """
        åŸºäºç›¸ä½çš„æ­¥æ€å¥–åŠ± - å¼ºåˆ¶å·¦å³è…¿äº¤æ›¿
        ä½¿ç”¨æ­£å¼¦æ³¢ç›¸ä½æ¥æŒ‡å®šå“ªåªè„šåº”è¯¥åœ¨æ‘†åŠ¨ç›¸
        """
        # æ›´æ–°æ­¥æ€ç›¸ä½
        has_command = torch.norm(self.commands[:, :2], dim=1) > 0.1
        self.gait_phase = torch.where(
            has_command,
            (self.gait_phase + self.dt * self.gait_frequency * 2 * 3.14159) % (2 * 3.14159),
            torch.zeros_like(self.gait_phase)
        )
        
        # ç›¸ä½ 0~Ï€: å·¦è„šåº”è¯¥æ‘†åŠ¨ (ç¦»åœ°)
        # ç›¸ä½ Ï€~2Ï€: å³è„šåº”è¯¥æ‘†åŠ¨ (ç¦»åœ°)
        left_should_swing = (self.gait_phase < 3.14159)  # 0~Ï€
        right_should_swing = ~left_should_swing  # Ï€~2Ï€
        
        # å®é™…æ¥è§¦çŠ¶æ€
        left_contact = self.contact_filt[:, 0]
        right_contact = self.contact_filt[:, 1]
        
        # å¥–åŠ±ï¼šå½“ç›¸ä½æŒ‡ç¤ºæŸè„šåº”è¯¥æ‘†åŠ¨æ—¶ï¼Œè¯¥è„šç¡®å®ç¦»åœ°
        left_correct = left_should_swing & ~left_contact  # å·¦è„šåº”æ‘†åŠ¨ä¸”ç¡®å®ç¦»åœ°
        right_correct = right_should_swing & ~right_contact  # å³è„šåº”æ‘†åŠ¨ä¸”ç¡®å®ç¦»åœ°
        
        # æƒ©ç½šï¼šå½“ç›¸ä½æŒ‡ç¤ºæŸè„šåº”è¯¥æ‘†åŠ¨æ—¶ï¼Œè¯¥è„šå´ç€åœ°
        left_wrong = left_should_swing & left_contact  # å·¦è„šåº”æ‘†åŠ¨ä½†ç€åœ°
        right_wrong = right_should_swing & right_contact  # å³è„šåº”æ‘†åŠ¨ä½†ç€åœ°
        
        reward = (left_correct.float() + right_correct.float()) * has_command.float()
        penalty = (left_wrong.float() + right_wrong.float()) * has_command.float() * 0.5
        
        return reward - penalty
    
    def _reward_foot_swing_symmetry(self):
        """
        æƒ©ç½šä¸å¯¹ç§°çš„æ‘†åŠ¨æ¨¡å¼ - é˜²æ­¢æ€»æ˜¯åŒä¸€åªè„šå…ˆè¿ˆæ­¥
        è¿½è¸ªå“ªåªè„šæœ€åæ‘†åŠ¨ï¼Œæƒ©ç½šè¿ç»­åŒä¸€åªè„šæ‘†åŠ¨
        """
        # æ£€æµ‹å“ªåªè„šåˆšä»ç€åœ°å˜ä¸ºç¦»åœ°ï¼ˆå¼€å§‹æ‘†åŠ¨ï¼‰
        left_start_swing = self.contact_over[:, 0]  # å·¦è„šåˆšç¦»åœ°
        right_start_swing = self.contact_over[:, 1]  # å³è„šåˆšç¦»åœ°
        
        # æ›´æ–°æœ€åæ‘†åŠ¨çš„è„š
        self.last_swing_foot = torch.where(left_start_swing, torch.zeros_like(self.last_swing_foot), self.last_swing_foot)
        self.last_swing_foot = torch.where(right_start_swing, torch.ones_like(self.last_swing_foot), self.last_swing_foot)
        
        # æƒ©ç½šè¿ç»­åŒä¸€åªè„šæ‘†åŠ¨
        # å¦‚æœå·¦è„šå¼€å§‹æ‘†åŠ¨ï¼Œä½†ä¸Šæ¬¡ä¹Ÿæ˜¯å·¦è„šæ‘†åŠ¨ -> æƒ©ç½š
        left_repeat = left_start_swing & (self.last_swing_foot == 0)
        right_repeat = right_start_swing & (self.last_swing_foot == 1)
        
        has_command = torch.norm(self.commands[:, :2], dim=1) > 0.1
        penalty = (left_repeat.float() + right_repeat.float()) * has_command.float()
        
        return -penalty
    
    def _reward_stuck(self):
        # Penalize stuck
        return (torch.abs(self.base_lin_vel[:, 0]) < 0.1) * (torch.abs(self.commands[:, 0]) > 0.1)
    
    def _reward_cheat(self):
        # penalty cheating to bypass the obstacle
        no_cheat_env = torch.logical_and(self.env_class != 0, self.env_class != 1)
        forward = quat_apply(self.base_quat[no_cheat_env], self.forward_vec[no_cheat_env])
        heading = torch.atan2(forward[:, 1], forward[:, 0])
        cheat = (heading > 1.0) | (heading < -1.0)
        cheat_penalty = torch.zeros(self.num_envs, device=self.device)
        cheat_penalty[no_cheat_env] = cheat.float()
        return cheat_penalty
    
    def _reward_feet_edge(self):
        foot_indicators_pos_xy = ((self.feet_indicator_pos[..., :2]+self.terrain.cfg.border_size) / self.cfg.terrain.horizontal_scale).round().long()
        foot_indicators_pos_xy[..., 0] = torch.clip(foot_indicators_pos_xy[..., 0], 0, self.x_edge_mask.shape[0]-1)
        foot_indicators_pos_xy[..., 1] = torch.clip(foot_indicators_pos_xy[..., 1], 0, self.x_edge_mask.shape[1]-1)

        feet_at_edge = self.x_edge_mask[foot_indicators_pos_xy[..., 0], foot_indicators_pos_xy[..., 1]]
        feet_at_edge = torch.sum(feet_at_edge, dim=-1) >= 2
        feet_at_edge = self.contact_filt & feet_at_edge
        rew = (self.terrain_levels > 3) * torch.sum(feet_at_edge, dim=1)
        return rew

    # def _reward_feet_edge(self):
    #     feet_pos_xy = ((self.rigid_body_states.view(self.num_envs, self.num_bodies, 13)[:, self.feet_indices, :2] + self.terrain.cfg.border_size) / self.cfg.terrain.horizontal_scale).round().long()  # (num_envs, 4, 2)
    #     feet_pos_xy[..., 0] = torch.clip(feet_pos_xy[..., 0], 0, self.x_edge_mask.shape[0]-1)
    #     feet_pos_xy[..., 1] = torch.clip(feet_pos_xy[..., 1], 0, self.x_edge_mask.shape[1]-1)
    #     feet_at_edge = self.x_edge_mask[feet_pos_xy[..., 0], feet_pos_xy[..., 1]]
    
    #     self.feet_at_edge = self.contact_filt & feet_at_edge
    #     rew = (self.terrain_levels > 3) * torch.sum(self.feet_at_edge, dim=-1)
    #     return rew
    
    def _reward_y_offset_pen(self):
        """
        æƒ©ç½šæœºå™¨äººåç¦»ç›´çº¿è·¯å¾„ï¼ˆYæ–¹å‘åç§»ï¼‰
        è¿™å¯¹äºä¿æŒç›´çº¿è¡Œèµ°éå¸¸é‡è¦
        """
        # è®¡ç®—ç›¸å¯¹äºèµ·å§‹Yä½ç½®çš„åç§»
        y_offset = torch.abs(self.root_states[:, 1] - self.origin_y)
        
        # åªåœ¨æœ‰å‰è¿›é€Ÿåº¦å‘½ä»¤æ—¶æƒ©ç½šæ¨ªå‘åç§»
        forward_cmd = torch.abs(self.commands[:, 0]) > 0.1
        
        # å¯¹äºéå¹³åœ°ç¯å¢ƒï¼ˆenv_class != 0 å’Œ != 1ï¼‰ï¼Œå¼ºåˆ¶ç›´çº¿è¡Œèµ°
        non_flat_env = torch.logical_and(self.env_class != 0, self.env_class != 1)
        
        # ç»„åˆæ¡ä»¶ï¼šæœ‰å‰è¿›å‘½ä»¤ æˆ– éå¹³åœ°ç¯å¢ƒ
        should_penalize = torch.logical_or(forward_cmd, non_flat_env)
        
        pen = y_offset * should_penalize.float()
        
        # åˆå§‹åŒ–æ‰“å°è®¡æ•°å™¨
        if not hasattr(self, '_y_offset_print_counter'):
            self._y_offset_print_counter = 0
        
        self._y_offset_print_counter += 1
        
        # æ¯ 100 æ­¥æ‰“å°ä¸€æ¬¡ç»Ÿè®¡
        if self._y_offset_print_counter % 100 == 0:
            mean_offset = y_offset.mean().item()
            max_offset = y_offset.max().item()
            penalized_envs = should_penalize.sum().item()
            print(f"[Yåç§»] å¹³å‡:{mean_offset:.3f}m | æœ€å¤§:{max_offset:.3f}m | æƒ©ç½šç¯å¢ƒæ•°:{penalized_envs}/{self.num_envs}")
        
        return pen

    def _reward_stand_still(self):
        """
        å¥–åŠ±åœ¨é›¶é€Ÿåº¦æŒ‡ä»¤æ—¶ä¿æŒé™æ­¢ç«™ç«‹
        å½“é€Ÿåº¦æŒ‡ä»¤æ¥è¿‘é›¶æ—¶ï¼Œæƒ©ç½šä»»ä½•èº«ä½“è¿åŠ¨
        """
        # æ£€æµ‹æ˜¯å¦æ˜¯é›¶é€Ÿåº¦æŒ‡ä»¤
        cmd_norm = torch.norm(self.commands[:, :2], dim=1)
        no_cmd = cmd_norm < 0.1  # é€Ÿåº¦æŒ‡ä»¤å°äº0.1m/sè§†ä¸ºé›¶é€Ÿåº¦
        
        # æƒ©ç½šèº«ä½“çº¿é€Ÿåº¦
        lin_vel_penalty = torch.sum(torch.square(self.base_lin_vel[:, :2]), dim=1)
        
        # æƒ©ç½šè„šéƒ¨é€Ÿåº¦ï¼ˆé˜²æ­¢åŸåœ°è¸æ­¥ï¼‰
        feet_vel_penalty = torch.sum(torch.norm(self.feet_vel, dim=-1), dim=1)
        
        # åªåœ¨é›¶é€Ÿåº¦æŒ‡ä»¤æ—¶åº”ç”¨æƒ©ç½š
        penalty = (lin_vel_penalty + 0.5 * feet_vel_penalty) * no_cmd.float()
        
        return penalty
    
    def _reward_feet_still_when_stand(self):
        """
        é›¶é€Ÿåº¦æ—¶å¥–åŠ±åŒè„šåŒæ—¶ç€åœ°ä¸”ä¿æŒé™æ­¢
        """
        cmd_norm = torch.norm(self.commands[:, :2], dim=1)
        no_cmd = cmd_norm < 0.1
        
        # åŒè„šéƒ½ç€åœ°
        both_contact = torch.all(self.contact_filt, dim=1)
        
        # è„šéƒ¨é€Ÿåº¦å¾ˆå°
        feet_vel_norm = torch.sum(torch.norm(self.feet_vel, dim=-1), dim=1)
        feet_still = feet_vel_norm < 0.1
        
        # å¥–åŠ±ï¼šé›¶é€Ÿåº¦ + åŒè„šç€åœ° + è„šé™æ­¢
        reward = (no_cmd & both_contact & feet_still).float()
        
        return reward

    def _reward_default_joint_pos(self):
        """
        Calculates the reward for keeping joint positions close to default positions, with a focus 
        on penalizing deviation in yaw and roll directions. Excludes yaw and roll from the main penalty.
        """
        joint_diff = self.dof_pos - self.default_dof_pos
        left_yaw_roll = joint_diff[:, :2]
        right_yaw_roll = joint_diff[:, 6: 8]
        yaw_roll = torch.norm(left_yaw_roll, dim=1) + torch.norm(right_yaw_roll, dim=1)
        yaw_roll = torch.clamp(yaw_roll - 0.1, 0, 50)
        return torch.exp(-yaw_roll * 100) - 0.01 * torch.norm(joint_diff, dim=1)


    def _reward_both_feet_same_height(self):
        """
        æƒ©ç½šåŒè„šåœ¨åŒä¸€é«˜åº¦ï¼ˆå¹¶æ­¥è¡Œä¸ºï¼‰
        åªåœ¨ä¸Šå¡/æ¥¼æ¢¯åœ°å½¢æ—¶æƒ©ç½šï¼Œå¹³åœ°ä¸æƒ©ç½š
        """
        # è·å–ä¸¤åªè„šçš„é«˜åº¦
        left_foot_height = self.feet_pos[:, 0, 2]
        right_foot_height = self.feet_pos[:, 1, 2]
        
        # è®¡ç®—é«˜åº¦å·®
        height_diff = torch.abs(left_foot_height - right_foot_height)
        
        # åŒè„šéƒ½ç€åœ°æ—¶
        both_contact = torch.all(self.contact_filt, dim=1)
        
        # æœ‰å‰è¿›é€Ÿåº¦å‘½ä»¤æ—¶
        has_forward_cmd = self.commands[:, 0] > 0.2  # åªåœ¨å‰è¿›æ—¶
        
        # æ£€æµ‹æ˜¯å¦åœ¨æ¥¼æ¢¯/æ–œå¡åœ°å½¢ï¼ˆenv_class > 1 é€šå¸¸æ˜¯éå¹³åœ°ï¼‰
        # æˆ–è€…é€šè¿‡è„šçš„ç»å¯¹é«˜åº¦åˆ¤æ–­ï¼šå¦‚æœè„šé«˜äºåˆå§‹é«˜åº¦ï¼Œè¯´æ˜åœ¨çˆ¬å¡
        on_elevated_terrain = (self.feet_pos[:, :, 2].mean(dim=1) > 0.20)  # è„šå¹³å‡é«˜åº¦ > 10cm
        
        # é«˜åº¦å·®å°äºé˜ˆå€¼ï¼ˆæ¯”å¦‚8cmï¼‰æ—¶æƒ©ç½š - è¯´æ˜æ˜¯å¹¶æ­¥
        same_height = height_diff < 0.08
        
        # åªåœ¨ï¼šæœ‰å‰è¿›å‘½ä»¤ + åŒè„šç€åœ° + é«˜åº¦å·®å° + åœ¨é«˜åœ°å½¢æ—¶æƒ©ç½š
        penalty = (both_contact & has_forward_cmd & same_height & on_elevated_terrain).float()
        
        return penalty

    def _reward_step_forward_alternating(self):
        """
        å¥–åŠ±äº¤æ›¿å‘å‰è¿ˆæ­¥ - é˜²æ­¢å¹¶æ­¥è¡Œä¸º
        æ£€æµ‹ï¼šå¦‚æœä¸€åªè„šç€åœ°ï¼Œä½†ä½ç½®åœ¨å¦ä¸€åªè„šåé¢ï¼Œè¯´æ˜æ˜¯å¹¶æ­¥
        """
        # è·å–è„šåœ¨èº«ä½“åæ ‡ç³»ä¸­çš„ä½ç½®
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
        
        # å½“å‰è„šçš„å‰è¿›ä½ç½®ï¼ˆXæ–¹å‘ï¼‰
        left_foot_x = footpos_in_body_frame[:, 0, 0]
        right_foot_x = footpos_in_body_frame[:, 1, 0]
        
        # æ£€æµ‹è„šåˆšç€åœ°ï¼ˆä»ç¦»åœ°å˜ä¸ºç€åœ°ï¼‰
        left_just_landed = self.contact_filt[:, 0] & (~self.last_contacts[:, 0])
        right_just_landed = self.contact_filt[:, 1] & (~self.last_contacts[:, 1])
        
        # æœ‰å‰è¿›é€Ÿåº¦å‘½ä»¤æ—¶
        has_forward_cmd = self.commands[:, 0] > 0.2
        
        # å½“å·¦è„šç€åœ°æ—¶ï¼Œæ£€æŸ¥å®ƒæ˜¯å¦åœ¨å³è„šå‰é¢ï¼ˆæ­£å¸¸ï¼‰è¿˜æ˜¯åé¢ï¼ˆå¹¶æ­¥ï¼‰
        # æ­£å¸¸ï¼šå·¦è„šåœ¨å³è„šå‰é¢è‡³å°‘ 5cm
        left_ahead_of_right = left_foot_x > (right_foot_x + 0.10)
        left_behind_right = left_foot_x < (right_foot_x - 0.10)  # å¹¶æ­¥ï¼šå·¦è„šåœ¨å³è„šåé¢
        
        # å½“å³è„šç€åœ°æ—¶ï¼Œæ£€æŸ¥å®ƒæ˜¯å¦åœ¨å·¦è„šå‰é¢ï¼ˆæ­£å¸¸ï¼‰è¿˜æ˜¯åé¢ï¼ˆå¹¶æ­¥ï¼‰
        right_ahead_of_left = right_foot_x > (left_foot_x + 0.10)
        right_behind_left = right_foot_x < (left_foot_x - 0.10)  # å¹¶æ­¥ï¼šå³è„šåœ¨å·¦è„šåé¢
        
        # å¥–åŠ±ï¼šç€åœ°æ—¶åœ¨å¯¹ä¾§è„šå‰é¢
        left_reward = (left_just_landed & has_forward_cmd & left_ahead_of_right).float() * torch.clamp(left_foot_x - right_foot_x, 0, 0.5)
        right_reward = (right_just_landed & has_forward_cmd & right_ahead_of_left).float() * torch.clamp(right_foot_x - left_foot_x, 0, 0.5)
        
        # æƒ©ç½šï¼šç€åœ°æ—¶åœ¨å¯¹ä¾§è„šåé¢ï¼ˆå¹¶æ­¥è¡Œä¸ºï¼‰
        left_penalty = (left_just_landed & has_forward_cmd & left_behind_right).float()
        right_penalty = (right_just_landed & has_forward_cmd & right_behind_left).float()
        
        # æ›´æ–°æœ€è¿œä½ç½®ï¼ˆç”¨äºè°ƒè¯•ï¼Œä½†ä¸ç”¨äºå¥–åŠ±è®¡ç®—ï¼‰
        self.feet_max_forward_pos[:, 0] = torch.maximum(self.feet_max_forward_pos[:, 0], left_foot_x)
        self.feet_max_forward_pos[:, 1] = torch.maximum(self.feet_max_forward_pos[:, 1], right_foot_x)
        
        return left_reward + right_reward - 2.0 * (left_penalty + right_penalty)

    # === æ–°å¢ [2026-01-23]: æ¥¼æ¢¯æ”€çˆ¬æ ¸å¿ƒå¥–åŠ±å‡½æ•°ç»„åˆæ‹³ ===
    
    def _reward_height_scan_gradient_clearance(self):
        """
        [æ ¸å¿ƒå¥–åŠ± 1] åŸºäºåœ°å½¢æ‰«æçš„è‡ªé€‚åº”æŠ¬è„š + è®°å¿†åŠŸèƒ½
        ä¿®æ”¹åŠ¨æœº: è§£å†³ä¸Šæ¥¼æ¢¯æŠ¬è…¿é«˜åº¦ä¸è¶³ & æ¥¼æ¢¯é¡¶éƒ¨ç›²åŒºå¯¼è‡´çš„æ‘”å€’ã€‚
                 å¼•å…¥è®°å¿†æœºåˆ¶(avg_obstacle_height)ï¼Œå³ä½¿è§†è§‰çœ‹åˆ°å¹³åœ°ï¼Œä¹Ÿèƒ½ä¿æŒä¸€æ®µæ—¶é—´é«˜æŠ¬è…¿ï¼Œç¡®ä¿åè…¿å®‰å…¨ä¸Šå²¸ã€‚
        """
        if not self.cfg.terrain.measure_heights:
            return torch.zeros(self.num_envs, device=self.device)
        
        # 1. åˆå§‹åŒ–è®°å¿†å˜é‡
        if not hasattr(self, 'avg_obstacle_height'):
            self.avg_obstacle_height = torch.zeros(self.num_envs, device=self.device)
        
        # 2. è·å–åœ°å½¢ä¿¡æ¯
        # measured_heights æ˜¯ (num_envs, num_points)ï¼Œé€šå¸¸å®šä¹‰ä¸º base_z - terrain_z
        # å¦‚æœæ˜¯æ­£å€¼å¹¶ä¸”å¾ˆå¤§ï¼Œè¯´æ˜åœ°é¢å¾ˆä½ï¼ˆæ‚¬å´–ï¼‰ã€‚å¦‚æœæ˜¯è´Ÿå€¼ï¼Œè¯´æ˜åœ°é¢é«˜äºé¢„æœŸï¼ˆä½†è¿™å–å†³äº specifically implementationï¼‰ã€‚
        # é€šå¸¸ legged_gym ä¸­ measured_heights = clip(root_z - cfg.base_height - terrain_height, -1, 1)
        # æ‰€ä»¥ terrain_height = root_z - cfg.base_height - measured_heights
        # å¦‚æœå‰æ–¹æœ‰å°é˜¶ï¼Œterrain_height å˜é«˜ï¼Œ measured_heights å˜å° (ç”šè‡³ä¸ºè´Ÿ)ã€‚
        # ä½ çš„ä»£ç ä¸­: heights = torch.clip(self.root_states[:, 2].unsqueeze(1) - self.cfg.normalization.base_height - self.measured_heights, -1, 1.)
        # ç­‰ç­‰ï¼Œé€šå¸¸ self.measured_heights æ˜¯ä»åœ°å½¢é‡‡æ ·çš„åŸå§‹é«˜åº¦å€¼å—ï¼Ÿæˆ–è€…å·²ç»æ˜¯ç›¸å¯¹å€¼ï¼Ÿ
        # åœ¨ _get_heights() ä¸­ï¼š 
        # points = quat_apply_yaw_inverse(self.base_quat, self.measured_points) + (self.root_states[:, :3]).unsqueeze(1)
        # heights = self.terrain.height_field_raw[x, y] * self.terrain.vertical_scale
        # æ‰€ä»¥ self.measured_heights é€šå¸¸æ˜¯ä¸–ç•Œåæ ‡ç³»ä¸‹çš„åœ°å½¢ç»å¯¹é«˜åº¦ã€‚
        
        # æˆ‘ä»¬éœ€è¦è®¡ç®—éšœç¢ç‰©ç›¸å¯¹äºè„šçš„é«˜åº¦ã€‚
        # ç®€åŒ–ç®—æ³•ï¼šä½¿ç”¨ measured_heights (ä¸–ç•Œç»å¯¹é«˜åº¦) -è„šä¸‹åœ°é¢é«˜åº¦
        
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ç›´æ¥è§‚æµ‹ measured_heights çš„å˜åŒ–æ¢¯åº¦
        # æˆ–è€…ä½¿ç”¨å…ˆå‰é€»è¾‘ï¼šå¦‚æœmeasured_heightsä¸­å‰æ–¹ç‚¹æ¯”å½“å‰è„šä¸‹é«˜
        
        # å‡è®¾ self.measured_heights å­˜å‚¨çš„æ˜¯åœ°å½¢é«˜åº¦é‡‡æ ·å€¼ (scalar)
        
        # æ³¨æ„ï¼šä½ åœ¨ä¹‹å‰çš„åˆ†æä¸­æåˆ° "heights = -self.measured_heights # å–è´Ÿå€¼ï¼Œæ­£å€¼è¡¨ç¤ºæœ‰å‡¸èµ·"
        # è¿™å–å†³äº measured_heights åœ¨ observations ä¸­çš„å¤„ç†æ–¹å¼ã€‚
        # åŸç”Ÿ legged_gym ä¸­ï¼š
        # self.measured_heights æ˜¯ update_height_scanning å¾—åˆ°çš„ absolute z values of terrain.
        # åœ¨ compute_observations ä¸­ï¼š
        # heights = clip(root_z - 0.5 - measured_heights, -1, 1) * scale
        # æ‰€ä»¥ obs é‡Œçš„ height æ˜¯ "base é«˜å‡ºåœ°é¢çš„é‡"ã€‚å€¼è¶Šå°ï¼Œè¯´æ˜åœ°é¢è¶Šé«˜ï¼ˆç¦»baseè¶Šè¿‘ï¼‰ã€‚
        
        # è¿™é‡Œä¸ºäº†ç¨³å¥ï¼Œç›´æ¥ä½¿ç”¨è§‚æµ‹åˆ°çš„ç»å¯¹åœ°å½¢é«˜åº¦ self.measured_heights
        heights = self.measured_heights # (num_envs, num_points)
        
        # è¿™æ˜¯ä¸€ä¸ªç»å¯¹é«˜åº¦å€¼ã€‚æˆ‘ä»¬éœ€è¦è®¡ç®—"ç›¸å¯¹äºå½“å‰åœ°é¢"çš„å‡¸èµ·é«˜åº¦ã€‚
        # å–è„šéƒ¨é«˜åº¦ä½œä¸ºå‚è€ƒåœ°å¹³é¢
        feet_height_min = torch.min(self.feet_pos[:, :, 2], dim=1)[0] # (num_envs,)
        
        # è®¡ç®—åœ°å½¢ç›¸å¯¹äºè„šçš„é«˜åº¦
        relative_terrain_height = heights - feet_height_min.unsqueeze(1)
        
        # è¿‡æ»¤ï¼šåªå…³å¿ƒæ¯”è„šé«˜çš„åœ°æ–¹
        positive_heights = torch.clamp(relative_terrain_height, min=0)
        
        # å–æ‰«æèŒƒå›´å†…æœ€é«˜çš„ 10% ç‚¹çš„å¹³å‡å€¼ï¼Œä½œä¸º"æœ‰æ•ˆéšœç¢ç‰©é«˜åº¦"
        k = max(1, int(heights.shape[1] * 0.1))
        top_heights, _ = torch.topk(positive_heights, k, dim=1)
        effective_obstacle_height = torch.mean(top_heights, dim=1)
        
        # 3. æ›´æ–°è®°å¿† (å…³é”®é€»è¾‘ï¼šè§£å†³é¡¶éƒ¨ç›²åŒº)
        # diff > 0 (çœ‹åˆ°å°é˜¶): alpha = 0.5 (å¿«é€Ÿååº”ï¼Œç«‹åˆ»æŠ¬è…¿)
        # diff < 0 (çœ‹åˆ°å¹³åœ°): alpha = 0.02 (ææ…¢è¡°å‡ï¼Œä¿æŒé«˜æŠ¬è…¿çŠ¶æ€çº¦1-2ç§’)
        diff = effective_obstacle_height - self.avg_obstacle_height
        alpha = torch.where(diff > 0, 
                            torch.ones_like(diff) * 0.5, 
                            torch.ones_like(diff) * 0.02)
        self.avg_obstacle_height = self.avg_obstacle_height + alpha * diff
        
        # 4. è®¡ç®—åŠ¨æ€ç›®æ ‡é«˜åº¦
        base_clearance = self.cfg.rewards.clearance_height_target  # ä¾‹å¦‚ -0.49
        # éšœç¢ç‰©é«˜åº¦é™åˆ¶ï¼Œé˜²æ­¢è¿‡é«˜
        obstacle_level = torch.clamp(self.avg_obstacle_height, min=0, max=0.30)
        # ç›®æ ‡é«˜åº¦ = åŸºç¡€ + éšœç¢ç‰©é«˜åº¦ * 1.2 (ç•™å‡ºå®‰å…¨ä½™é‡)
        # æ³¨æ„: base_clearance æ˜¯è´Ÿæ•° (foot_z - base_z)ï¼Œobstacle_level æ˜¯æ­£æ•°
        # æˆ‘ä»¬å¸Œæœ›è„šæŠ¬å¾—æ›´é«˜ï¼Œå³ (foot_z - base_z) å˜å¤§ (æ›´æ¥è¿‘0ï¼Œæˆ–è€…æ­£æ•°)
        # æ¯”å¦‚ base_z=0.5, foot_z=0 -> clearance=-0.5
        # é‡åˆ°0.2må°é˜¶ï¼Œå¸Œæœ› foot_z=0.25 -> clearance=-0.25
        # æ‰€ä»¥ target = base_clearance + obstacle_level
        target_clearance = base_clearance + obstacle_level * 1.2
        
        # 5. è®¡ç®—æƒ©ç½š
        # è·å–è„šç›¸å¯¹äº base çš„ Z åæ ‡
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
        
        foot_z_body = footpos_in_body_frame[:, :, 2]  # è„šç›¸å¯¹äº base çš„ Z åæ ‡
        
        # åªåœ¨æ‘†åŠ¨ç›¸è®¡ç®—
        is_swing = ~self.contact_filt
        
        # è¯¯å·®è®¡ç®—ï¼šåªæƒ©ç½šä½äºç›®æ ‡é«˜åº¦çš„æƒ…å†µ (å³è„šå¤ªä½äº†)
        # target_clearance æ˜¯æœŸæœ›çš„æœ€ä½é«˜åº¦ (ä¾‹å¦‚ -0.25)
        # foot_z_body æ˜¯å®é™…é«˜åº¦ (ä¾‹å¦‚ -0.4)
        # æˆ‘ä»¬å¸Œæœ› foot_z_body >= target_clearance
        # æ‰€ä»¥ error = clamp(target - actual, min=0) => clamp(-0.25 - (-0.4), 0) = 0.15
        height_error = torch.clamp(target_clearance.unsqueeze(1) - foot_z_body, min=0.0)
        
        # é€Ÿåº¦åŠ æƒï¼šä¸‹è½é˜¶æ®µ (vz < 0) å¦‚æœé«˜åº¦ä¸å¤Ÿï¼Œæå…¶å±é™©ï¼Œç»™äºˆé‡ç½š
        foot_vz = self.feet_vel[:, :, 2]
        vel_penalty = torch.where(foot_vz < 0, 
                                torch.ones_like(foot_vz) * 2.0, 
                                torch.ones_like(foot_vz) * 1.0)
        
        return torch.sum(torch.square(height_error) * vel_penalty * is_swing.float(), dim=1)


    def _reward_feet_toe_collision(self):
        """
        [æ ¸å¿ƒå¥–åŠ± 2] æƒ©ç½šè„šéƒ¨å—åˆ°æ°´å¹³æ’å‡»
        ä¿®æ”¹åŠ¨æœº: è§£å†³ä¸Šæ¥¼æ­¥å¹…è¿‡å¤§ï¼Œå¯¼è‡´è„šå°–è¸¢åˆ°å°é˜¶å‚ç›´é¢ã€‚è¿™æ˜¯â€œç—›è§‰â€åé¦ˆã€‚
        é€šè¿‡æ£€æµ‹æ°´å¹³æ¥è§¦åŠ›æ˜¯å¦è¿œå¤§äºå‚ç›´åŠ›ï¼Œåˆ¤æ–­æ˜¯å¦å‘ç”Ÿäº†è¸¢æ’ã€‚
        """
        # è·å–æ¥è§¦åŠ› (num_envs, 2, 3)
        contact_forces = self.contact_forces[:, self.feet_indices, :]
        
        # è®¡ç®—æ°´å¹³åŠ›å’Œå‚ç›´åŠ›
        horizontal_force = torch.norm(contact_forces[..., :2], dim=-1)  # XY å¹³é¢
        vertical_force = torch.abs(contact_forces[..., 2])  # Z è½´
        
        # åˆ¤å®šé€»è¾‘ï¼š
        # 1. å¿…é¡»æœ‰æ˜¾è‘—çš„æ¥è§¦åŠ› (> 10N)
        # 2. æ°´å¹³åŠ›æ˜¾è‘—å¤§äºå‚ç›´åŠ›çš„ä¸€å®šæ¯”ä¾‹ (ä¾‹å¦‚ > 0.5 * Fz)
        # æ­£å¸¸ç«™ç«‹æ—¶ Fz å¾ˆå¤§ï¼ŒFxy å¾ˆå°
        # è¸¢åˆ°å°é˜¶æ—¶ Fxy å¾ˆå¤§ï¼ŒFz å¯èƒ½è¾ƒå°æˆ–ä¸­ç­‰
        total_force = torch.norm(contact_forces, dim=-1)
        is_collision = (horizontal_force > vertical_force * 0.5) & (total_force > 10.0)
        
        # è¿”å›ç¢°æ’æ¬¡æ•°
        return torch.sum(is_collision.float(), dim=1)


    def _reward_stair_reach_penalty(self):
        """
        [æ ¸å¿ƒå¥–åŠ± 3] æ¥¼æ¢¯ä¸Šçš„æ­¥å¹…é™åˆ¶
        ä¿®æ”¹åŠ¨æœº: è¾…åŠ©é˜²æ­¢æ­¥å¹…è¿‡å¤§ï¼Œé¿å…æœºå™¨äººä¸ºäº†è¿½é€Ÿåº¦è€Œå¼ºè¡Œè¿ˆå¤§æ­¥ã€‚
        æ ¹æ®åœ°å½¢è®°å¿†å˜é‡åˆ¤æ–­æ˜¯å¦åœ¨æ¥¼æ¢¯ä¸Šï¼Œå¦‚æœåœ¨ï¼Œåˆ™é™åˆ¶è„šç¦»èº«ä½“è¿‡è¿œã€‚
        """
        # 1. åˆ¤æ–­æ˜¯å¦åœ¨æ¥¼æ¢¯/å¤æ‚åœ°å½¢ä¸Š
        if hasattr(self, 'avg_obstacle_height'):
            # å¦‚æœè®°å¿†ä¸­çš„éšœç¢é«˜åº¦ > 5cmï¼Œè®¤ä¸ºåœ¨æ¥¼æ¢¯æ¨¡å¼
            on_stair = self.avg_obstacle_height > 0.05
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨è„šçš„å®é™…é«˜åº¦
            feet_height = self.feet_pos[:, :, 2].max(dim=1)[0]
            on_stair = feet_height > 0.15
        
        # 2. è®¡ç®—è„šç›¸å¯¹äº Base çš„æ°´å¹³è·ç¦»
        cur_footpos_translated = self.feet_pos - self.root_states[:, 0:3].unsqueeze(1)
        footpos_in_body_frame = torch.zeros(self.num_envs, len(self.feet_indices), 3, device=self.device)
        for i in range(len(self.feet_indices)):
            footpos_in_body_frame[:, i, :] = quat_rotate_inverse(self.base_quat, cur_footpos_translated[:, i, :])
        
        # åªçœ‹ XY å¹³é¢è·ç¦»
        dist = torch.norm(footpos_in_body_frame[..., :2], dim=-1)
        
        # 3. è®¾å®šé˜ˆå€¼ï¼šå¹³åœ°æ­¥å¹…å…è®¸ 0.4m+ï¼Œä½†åœ¨æ¥¼æ¢¯ä¸Šå»ºè®®é™åˆ¶åœ¨ 0.32m
        limit = 0.32
        
        # 4. è®¡ç®—è¶…å‡ºéƒ¨åˆ†çš„æƒ©ç½š
        over_reach = torch.clamp(dist - limit, min=0)
        
        # åªæœ‰åœ¨æ¥¼æ¢¯ä¸Šæ‰æƒ©ç½šæ­¥å¹…è¿‡å¤§
        return torch.sum(over_reach * on_stair.unsqueeze(1).float(), dim=1)


    def _reward_feet_collision_pen(self):
        # Penalize feet hitting vertical surfaces
        foot_indicators_pos_xy = ((self.feet_collision_indicator_pos[..., :2]+self.terrain.cfg.border_size) / self.cfg.terrain.horizontal_scale).round().long()
        foot_indicators_pos_xy[..., 0] = torch.clip(foot_indicators_pos_xy[..., 0], 0, self.x_edge_mask.shape[0]-1)
        foot_indicators_pos_xy[..., 1] = torch.clip(foot_indicators_pos_xy[..., 1], 0, self.x_edge_mask.shape[1]-1)
        # stair
        up_stair_feet_collision = self.stair_pen_mask[0][foot_indicators_pos_xy[:, :, 0, 0], foot_indicators_pos_xy[:, :, 0, 1]] * self.contact_filt
        down_stair_feet_collision = self.stair_pen_mask[1][foot_indicators_pos_xy[:, :, 1, 0], foot_indicators_pos_xy[:, :, 1, 1]] * self.contact_filt
        stair_num_indicator_in_pen_area = torch.sum(up_stair_feet_collision, dim=-1) + torch.sum(down_stair_feet_collision, dim=-1)
        # pit
        pit_feet_collision = self.x_edge_mask[foot_indicators_pos_xy[:, :, 0, 0], foot_indicators_pos_xy[:, :, 0, 1]] * self.contact_filt
        pit_num_indicator_in_pen_area = torch.sum(pit_feet_collision, dim=-1)
        return pit_num_indicator_in_pen_area * (self.env_class == 1) + stair_num_indicator_in_pen_area * (self.env_class == 3)
